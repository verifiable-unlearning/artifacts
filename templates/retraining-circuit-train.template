
import "utils/casts/u64_to_bits" as u64_to_bits
import "utils/casts/u64_to_field" as u64_to_field
from "./poseidon/poseidon" import poseidon_hash_2 as hash

const u32 MAX_SAMPLES_D_PREV = {{max_samples_D_prev}}
const u32 MAX_SAMPLES_U_PREV = {{max_samples_U_prev}}
const u32 MAX_SAMPLES_D_PLUS = {{max_samples_D_plus}}
const u32 MAX_SAMPLES_D = {{max_samples_D_prev+max_samples_D_plus}}
const u64 PRECISION = {{precision}}
const u32 EPOCHS = {{epochs}}
const u64 LR = {{lr}}
const u32 NO_FEATURES = {{no_features}}
const u32 NO_WEIGHTS = {{no_weights}}
const u32 NO_NEURONS = {{no_neurons}}

def hash_input(u64[NO_FEATURES] x, u64 y) -> field:
    field h = hash(u64_to_field(y), u64_to_field(x[0]))
    for u32 j in 1..NO_FEATURES do
        h = hash(h, u64_to_field(x[j]))
    endfor
    return h

def remove_shift(u64 input) -> u64:
    return if u64_to_bits(input)[0] == true then  -1* ((-1 * input) / PRECISION ) else input / PRECISION fi

{%- if logistic_regression or neural_network %}
const u64 W0 = {{W0}}
const u64 W1 = {{W1}}
const u64 W3 = {{W3}}
def sigmoid(u64 x) -> u64:
    return W0 + remove_shift(W1*x) - remove_shift(W3*remove_shift(remove_shift(x*x)*x))
{% endif %}

def main(public field h_D_prev, public field h_D, public field h_m, public field h_U_prev, public field h_U, private u32 no_samples_D_prev, private u64[MAX_SAMPLES_D_PREV][NO_FEATURES] D_prev_X, private u64[MAX_SAMPLES_D_PREV] D_prev_Y, private u32 no_samples_U_prev, private field[MAX_SAMPLES_U_PREV] H_U_prev, private u32 no_samples_D_plus, private u64[MAX_SAMPLES_D_PLUS][NO_FEATURES] D_plus_X, private u64[MAX_SAMPLES_D_PLUS] D_plus_Y) -> field:

    // (a)
    field[MAX_SAMPLES_D_PREV] H_D_prev = [0; MAX_SAMPLES_D_PREV]
    for u32 i in 0..MAX_SAMPLES_D_PREV do
        H_D_prev[i] = if i < no_samples_D_prev then hash_input(D_prev_X[i], D_prev_Y[i]) else 0 fi
    endfor
    
    // (b)
    field h_D_prev_prime = hash(0, 0)
    for u32 i in 0..MAX_SAMPLES_D_PREV do
        h_D_prev_prime = if i < no_samples_D_prev then hash(h_D_prev_prime, H_D_prev[i]) else h_D_prev_prime fi
    endfor
    assert(h_D_prev_prime == h_D_prev)

    // (c)
    field h_U_prev_prime = hash(0, 0)
    for u32 i in 0..MAX_SAMPLES_U_PREV do
        h_U_prev_prime = if i < no_samples_U_prev then hash(h_U_prev_prime, H_U_prev[i]) else h_U_prev_prime fi
    endfor
    assert(h_U_prev_prime == h_U_prev)

    // (d)
    field[MAX_SAMPLES_D_PLUS] H_D_plus = [0; MAX_SAMPLES_D_PLUS]
    for u32 i in 0..MAX_SAMPLES_D_PLUS do
        H_D_plus[i] = if i < no_samples_D_plus then hash_input(D_plus_X[i], D_plus_Y[i]) else 0 fi        
    endfor

    // (f)
    field h_D_prime = h_D_prev
    for u32 i in 0..MAX_SAMPLES_D_PLUS do
        h_D_prime = if i < no_samples_D_plus then hash(h_D_prime, H_D_plus[i]) else h_D_prime fi
    endfor
    assert(h_D_prime == h_D)

    // (g)
    assert(h_U_prev == h_U)

    // (h)
    for u32 i in 0..MAX_SAMPLES_U_PREV do
        for u32 j in 0..MAX_SAMPLES_D_PLUS do
            field h_U_i = if i < no_samples_U_prev then H_U_prev[i] else 0 fi
            field h_D_plus_j = if j < no_samples_D_plus then H_D_plus[j] else -1 fi
            assert(h_U_i != h_D_plus_j)
        endfor
    endfor

    // (j)
    {{weights_init_str}}

    for u32 epoch in 0..EPOCHS do
        for u32 sample_idx in 0..MAX_SAMPLES_D_PREV do
            // init accumulator
            {%- if linear_regression or logistic_regression %}
            u64[NO_FEATURES] dw = [0; NO_FEATURES]
            u64 db = 0
            {% endif %}
            {%- if neural_network %}
            u64[NO_NEURONS] a_0 = [0; NO_NEURONS]
            u64 a_1 = 0
            u64[NO_NEURONS] z_0 = [0; NO_NEURONS]
            u64 z_1 = 0
            u64[NO_NEURONS] da_0 = [0; NO_NEURONS]
            u64[NO_NEURONS] dz_0 = [0; NO_NEURONS]
            u64 dz_1 = 0
            {%- for j in range(no_neurons) %}
            u64[NO_FEATURES] dw_0_{{j}} = [0; NO_FEATURES]
            {%- endfor %}
            u64[NO_NEURONS] dw_1_0 = [0; NO_NEURONS]
            u64[NO_NEURONS] db_0 = [0; NO_NEURONS]
            u64 db_1 = 0
            {% endif %}

            // get sample
            u64[NO_FEATURES] x = D_prev_X[sample_idx]
            u64 y = D_prev_Y[sample_idx]

            // forward
            {%- if linear_regression or logistic_regression %}
            u64 y_pred = b
            for u32 i in 0..NO_FEATURES do
                y_pred = y_pred + remove_shift(x[i]*w[i])
            endfor
            {% endif %}
            {%- if logistic_regression %}
            y_pred = sigmoid(y_pred)
            {% endif %}
            {%- if neural_network %}
            {%- for j in range(no_neurons) %}
            // j-th neuron
            z_0[{{j}}] = b_0[{{j}}]
            for u32 i in 0..NO_FEATURES do
                z_0[{{j}}] = z_0[{{j}}] + remove_shift(x[i]*w_0_{{j}}[i])
            endfor
            a_0[{{j}}] = sigmoid(z_0[{{j}}])
            {%- endfor %}
            // layer 1
            z_1 = b_1
            for u32 j in 0..NO_NEURONS do
                z_1 = z_1 + remove_shift(a_0[j]*w_1_0[j])
            endfor
            a_1 = sigmoid(z_1)
            {% endif %}  

            // backward
            {%- if linear_regression or logistic_regression %}
            u64 dy_pred = y_pred - y
            for u32 i in 0..NO_FEATURES do
                dw[i] = dw[i] + remove_shift(x[i]*dy_pred)
            endfor
            db = db + dy_pred
            {% endif %}
            {%- if neural_network %}
            // layer 1
            dz_1 = a_1 - y
            for u32 i in 0..NO_NEURONS do
                dw_1_0[i] = dw_1_0[i] + remove_shift(dz_1*a_0[i])
            endfor
            db_1 = db_1 + dz_1
            // layer 0 
            for u32 j in 0..NO_NEURONS do
                da_0[j] = remove_shift(dz_1*w_1_0[j])
            endfor
            for u32 j in 0..NO_NEURONS do
                dz_0[j] = remove_shift(da_0[j]*remove_shift(a_0[j]*(1-a_0[j])))
            endfor
            {%- for j in range(no_neurons) %}
                for u32 i in 0..NO_FEATURES do
                    dw_0_{{j}}[i] = dw_0_{{j}}[i] + remove_shift(dz_0[{{j}}] * x[i])
                endfor
            db_0[{{j}}] = db_0[{{j}}] + dz_0[{{j}}]
            {% endfor %}
            {% endif %}

            // update
            {%- if linear_regression or logistic_regression %}
            for u32 i in 0..NO_FEATURES do
                w[i] = if sample_idx < no_samples_D_prev then w[i] - remove_shift(LR * dw[i]) else w[i] fi
            endfor
            b = if sample_idx < no_samples_D_prev then b - remove_shift(LR * db) else b fi
            {% endif %}
            {%- if neural_network %}
            for u32 i in 0..NO_NEURONS do
                w_1_0[i] = if sample_idx < no_samples_D_prev then w_1_0[i] - remove_shift(LR*dw_1_0[i]) else w_1_0[i] fi
            endfor
            b_1 = if sample_idx < no_samples_D_prev then b_1 - remove_shift(LR*db_1) else b_1 fi

            {%- for j in range(no_neurons) %}    
            for u32 i in 0..NO_FEATURES do
                w_0_{{j}}[i] = if sample_idx < no_samples_D_prev then w_0_{{j}}[i] - remove_shift(LR*dw_0_{{j}}[i]) else w_0_{{j}}[i] fi
            endfor
            b_0[{{j}}] = if sample_idx < no_samples_D_prev then b_0[{{j}}] - remove_shift(LR*db_0[{{j}}]) else b_0[{{j}}] fi
            {% endfor %}
            {% endif %}
        endfor
        for u32 sample_idx in 0..MAX_SAMPLES_D_PLUS do
            // init accumulator
            {%- if linear_regression or logistic_regression %}
            u64[NO_FEATURES] dw = [0; NO_FEATURES]
            u64 db = 0
            {% endif %}
            {%- if neural_network %}
            u64[NO_NEURONS] a_0 = [0; NO_NEURONS]
            u64 a_1 = 0
            u64[NO_NEURONS] z_0 = [0; NO_NEURONS]
            u64 z_1 = 0
            u64[NO_NEURONS] da_0 = [0; NO_NEURONS]
            u64[NO_NEURONS] dz_0 = [0; NO_NEURONS]
            u64 dz_1 = 0
            {%- for j in range(no_neurons) %}
            u64[NO_FEATURES] dw_0_{{j}} = [0; NO_FEATURES]
            {%- endfor %}
            u64[NO_NEURONS] dw_1_0 = [0; NO_NEURONS]
            u64[NO_NEURONS] db_0 = [0; NO_NEURONS]
            u64 db_1 = 0
            {% endif %}

            // get sample
            u64[NO_FEATURES] x = D_plus_X[sample_idx]
            u64 y = D_plus_Y[sample_idx]

            // forward
            {%- if neural_network %}
            {%- for j in range(no_neurons) %}
            // j-th neuron
            z_0[{{j}}] = b_0[{{j}}]
            for u32 i in 0..NO_FEATURES do
                z_0[{{j}}] = z_0[{{j}}] + remove_shift(x[i]*w_0_{{j}}[i])
            endfor
            a_0[{{j}}] = sigmoid(z_0[{{j}}])
            {%- endfor %}
            // layer 1
            z_1 = b_1
            for u32 j in 0..NO_NEURONS do
                z_1 = z_1 + remove_shift(a_0[j]*w_1_0[j])
            endfor
            a_1 = sigmoid(z_1)
            {% endif %}  
            {%- if linear_regression or logistic_regression %}
            u64 y_pred = b
            for u32 i in 0..NO_FEATURES do
                y_pred = y_pred + remove_shift(x[i]*w[i])
            endfor
            {% endif %}
            {%- if logistic_regression %}
            y_pred = sigmoid(y_pred)
            {% endif %}

            // backward
            {%- if linear_regression or logistic_regression %}
            u64 dy_pred = y_pred - y
            for u32 i in 0..NO_FEATURES do
                dw[i] = dw[i] + remove_shift(x[i]*dy_pred)
            endfor
            db = db + dy_pred
            {% endif %}
            {%- if neural_network %}
            // layer 1
            dz_1 = a_1 - y
            for u32 i in 0..NO_NEURONS do
                dw_1_0[i] = dw_1_0[i] + remove_shift(dz_1*a_0[i])
            endfor
            db_1 = db_1 + dz_1
            // layer 0 
            for u32 j in 0..NO_NEURONS do
                da_0[j] = remove_shift(dz_1*w_1_0[j])
            endfor
            for u32 j in 0..NO_NEURONS do
                dz_0[j] = remove_shift(da_0[j]*remove_shift(a_0[j]*(1-a_0[j])))
            endfor
            {%- for j in range(no_neurons) %}
                for u32 i in 0..NO_FEATURES do
                    dw_0_{{j}}[i] = dw_0_{{j}}[i] + remove_shift(dz_0[{{j}}] * x[i])
                endfor
            db_0[{{j}}] = db_0[{{j}}] + dz_0[{{j}}]
            {% endfor %}
            {% endif %}
            // update
            {%- if linear_regression or logistic_regression %}
            for u32 i in 0..NO_FEATURES do
                w[i] = if sample_idx < no_samples_D_plus then w[i] - remove_shift(LR * dw[i]) else w[i] fi
            endfor
            b = if sample_idx < no_samples_D_plus then b - remove_shift(LR * db) else b fi
            {% endif %}
            {%- if neural_network %}
            for u32 i in 0..NO_NEURONS do
                w_1_0[i] = if sample_idx < no_samples_D_plus then w_1_0[i] - remove_shift(LR*dw_1_0[i]) else w_1_0[i] fi
            endfor
            b_1 = if sample_idx < no_samples_D_plus then b_1 - remove_shift(LR*db_1) else b_1 fi

            {%- for j in range(no_neurons) %}    
            for u32 i in 0..NO_FEATURES do
                w_0_{{j}}[i] = if sample_idx < no_samples_D_plus then w_0_{{j}}[i] - remove_shift(LR*dw_0_{{j}}[i]) else w_0_{{j}}[i] fi
            endfor
            b_0[{{j}}] = if sample_idx < no_samples_D_plus then b_0[{{j}}] - remove_shift(LR*db_0[{{j}}]) else b_0[{{j}}] fi
            {% endfor %}
            {% endif %}
        endfor        
    endfor

    {%- if neural_network %}
    u64[NO_WEIGHTS] model = [
    {%- for j in range(no_neurons) -%}
        {{" "}}...w_0_{{j}},
    {%- endfor -%}
    ...b_0, ...w_1_0, b_1]
    {% endif %}

    {%- if linear_regression or logistic_regression %}
    u64[NO_WEIGHTS] model = [...w, b]
    {% endif %}

    field h_m_prime = hash(u64_to_field(model[0]), u64_to_field(model[1]))
    for u32 i in 2..NO_WEIGHTS do
        h_m_prime = hash(h_m_prime, u64_to_field(model[i]))
    endfor
    assert(h_m_prime == h_m)

    return 1